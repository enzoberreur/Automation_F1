# üèéÔ∏è Ferrari F1 IoT Smart Pit-Stop

Plateforme de t√©l√©m√©trie et de monitoring inspir√©e d'un mur des stands de Formule‚ÄØ1. Le d√©p√¥t rassemble :

- un simulateur de capteurs haute fr√©quence (HTTP + m√©triques Prometheus)‚ÄØ;
- un service de traitement (`stream-processor`)‚ÄØ;
- une stack d'observabilit√© (Prometheus + Grafana)‚ÄØ;
- des orchestrations Airflow pour la donn√©e batch.

L'objectif : fournir un environnement r√©aliste pour exp√©rimenter des pipelines IoT/streaming et des tableaux de bord strat√©giques.

---

## üö¶ D√©marrage rapide (tout en Docker)

Pr√©-requis : Docker, Docker Compose et `make`.

```bash
git clone https://github.com/enzoberreur/Automation_F1.git
cd Automation_F1
make start
```

Cette commande :
1. arr√™te toute ex√©cution pr√©c√©dente (`docker compose down --remove-orphans`) ;
2. reconstruit et d√©marre les conteneurs n√©cessaires ;
3. importe automatiquement les dashboards Grafana.

> ‚ÑπÔ∏è Les identifiants par d√©faut sont `admin / admin` pour Grafana et Airflow.

Une fois le stack pr√™t, acc√©dez au poste de commande principal : <http://localhost:3000/d/ferrari-strategy-dashboard>.

Pour arr√™ter et nettoyer :

```bash
make stop
```

Pour repartir de z√©ro (conteneurs arr√™t√©s + volumes supprim√©s) :

```bash
make clean
```

La commande supprime √©galement les dossiers `__pycache__` g√©n√©r√©s par Python.

----

## üß™ D√©marrage l√©ger (simulateur seul)

Pour tester uniquement le flux de t√©l√©m√©trie :

```bash
cd sensor-simulator
pip install -r requirements.txt
python main.py
```

Le simulateur publie :
- la t√©l√©m√©trie sur `http://localhost:8001/telemetry` (attendez-vous √† un message d'erreur si le `stream-processor` n'est pas d√©marr√©)‚ÄØ;
- les m√©triques Prometheus sur `http://localhost:8000/metrics`.

Consultez `sensor-simulator/README.md` pour un guide d√©taill√© (configuration, m√©triques, anomalies simul√©es).

---

## üîå Services & ports

| Service | R√¥le | Port local |
|---------|------|------------|
| sensor-simulator | G√©n√®re la t√©l√©m√©trie F1 et les m√©triques Prometheus | `8000` (metrics) |
| stream-processor | Re√ßoit la t√©l√©m√©trie, calcule des KPIs et expose des API | `8001` |
| prometheus | Collecte toutes les m√©triques | `9090` |
| grafana | Tableaux de bord temps r√©el | `3000` |
| airflow | Orchestration batch & maintenance de donn√©es | `8080` |
| cadvisor | Observabilit√© des conteneurs | `8082` |

La configuration Docker Compose se trouve dans `docker-compose.yml`. Les manifestes Kubernetes sont disponibles dans `k8s/` si vous souhaitez d√©ployer sur un cluster.

---

## üìä Dashboards Grafana

Les d√©finitions JSON des dashboards r√©sident dans `monitoring/` :

- `grafana_dashboard_main.json` ‚Äî vue op√©rations & thermique : vitesse, freins/pneus, anomalies, strat√©gie.
- `grafana_dashboard_strategy.json` ‚Äî suivi d√©taill√© des recommandations pit-stop (probabilit√© de fen√™tre, √©tat de la piste, timeline strat√©gie).
- `grafana_dashboard_data.json`, `grafana_dashboard_data_quality.json` ‚Äî analyses compl√©mentaires (d√©bit, fra√Æcheur, qualit√© de donn√©es).

Importer manuellement :

```bash
./import-dashboard.sh
```

ou passer par l‚ÄôUI Grafana (`Dashboards ‚Üí Import`) en collant le contenu JSON.

---

## üìà M√©triques cl√©s

Les dashboards s'appuient principalement sur :

- **Flux** : `ferrari_simulator_messages_generated_total`, `ferrari_simulator_messages_sent_total`, `ferrari_simulator_current_throughput_msg_per_sec` (toutes tagu√©es par `car_id`, `team`, `driver`).
- **Thermique** : `ferrari_simulator_brake_temp_*_celsius`, `ferrari_simulator_tire_temp_*_celsius`, `ferrari_simulator_engine_temp_celsius`.
- **Pneus & carburant** : `ferrari_simulator_tire_wear_percent`, `ferrari_simulator_fuel_remaining_kg`.
- **Strat√©gie** : `ferrari_simulator_lap_time_seconds`, `ferrari_simulator_stint_health_score`, `ferrari_simulator_pit_window_probability`, `ferrari_simulator_surface_condition_state`, `ferrari_simulator_strategy_recommendation_state`.

Toutes les m√©triques expos√©es par le simulateur sont d√©crites dans `sensor-simulator/README.md`. Celles du `stream-processor` sont consultables via `http://localhost:8001/metrics`.

---

## üó∫Ô∏è Architecture (aper√ßu)

1. **Sensor Simulator** ‚Äî orchestre 20 voitures (10 √©quipes officielles), applique anomalies et calcule des insights de strat√©gie.
2. **Stream Processor** ‚Äî consomme les √©v√©nements HTTP, calcule des KPI temps r√©el et persiste l‚Äô√©tat.
3. **Prometheus** ‚Äî scrappe le simulateur, le stream-processor, cAdvisor.
4. **Grafana** ‚Äî visualise la t√©l√©m√©trie, les insights de strat√©gie et la sant√© syst√®me.
5. **Airflow** ‚Äî planifie des jobs batch (relectures, calculs p√©riodiques, tests de qualit√©).

Le document `ARCHITECTURE.md` fournit une description compl√®te (diagrammes, flux d√©taill√©s, cas d'usage).

---

## üß≠ Pourquoi cette architecture ?

### 1. Ingestion HTTP + m√©triques Prometheus
- **Choix actuel** : un simulateur Python publie la t√©l√©m√©trie via une API HTTP et expose les m√©triques Prometheus sur le m√™me pod.
- **Pourquoi** : HTTP reste trivial √† faire tourner localement, ne n√©cessite aucun cluster Kafka et permet de brancher n‚Äôimporte quel outil de test (curl, Postman) quand on d√©veloppe les algorithmes.
- **Alternative envisag√©e** : un bus Kafka ou NATS pour de l‚Äôingestion massive. On le garde sous le coude car le simulateur sait d√©j√† produire du JSON compatible Kafka, mais on √©vite la dette op√©rationnelle tant que la charge reste inf√©rieure au million d‚Äô√©v√©nements/s.

### 2. Traitement temps r√©el monolithique
- **Choix actuel** : un `stream-processor` unique (FastAPI + worker interne) calcule les KPI et relaye les √©v√©nements critiques.
- **Pourquoi** : l‚Äôalgorithme m√©tier (recommandation pit-stop, anomalies) partage √©norm√©ment de contexte ; garder un seul processus simplifie la coh√©rence et permet d‚Äôit√©rer vite.
- **Alternative** : d√©couper en micro-services (d√©tection anomalies, scoring pit-stop, enrichissement) ou passer sur un moteur stream (Flink, Spark). Pertinent uniquement si l‚Äôon veut parall√©liser sur plusieurs n≈ìuds ou appliquer du ML temps r√©el.

### 3. Stockage orient√© s√©ries temporelles minimaliste
- **Choix actuel** : Prometheus uniquement pour les m√©triques temps r√©el, PostgreSQL pour l‚Äôhistorique batch.
- **Pourquoi** : Prometheus suffit pour des fen√™tres courtes (quelques heures) et Grafana sait interroger directement PromQL. PostgreSQL d√©j√† pr√©sent avec Airflow couvre les besoins d‚Äôarchives.
- **Alternatives** : TimescaleDB, InfluxDB ou ClickHouse si on doit requ√™ter plusieurs semaines/mois de t√©l√©m√©trie avec agr√©gations lourdes.

### 4. Dashboards provisionn√©s automatiquement
- **Choix actuel** : Grafana import√© par script (`import-dashboard.sh`) avec des JSON versionn√©s.
- **Pourquoi** : reproductibilit√© totale entre dev et prod, aucun clic manuel pour installer ou mettre √† jour un dashboard.
- **Alternative** : Terraform/Grafana API via CI. √Ä prioriser si plusieurs environnements doivent √™tre tenus √† jour par une √©quipe ops.

### 5. Batch orchestr√© par Airflow
- **Choix actuel** : Airflow + PostgreSQL + Redis pour les workloads diff√©r√©s (rejeu, ML offline, rapports).
- **Pourquoi** : l‚Äô√©cosyst√®me Airflow est standard en data eng, offre des hooks SQL/HTTP, et r√©utilise PostgreSQL/Redis d√©j√† n√©cessaires √† Grafana et au simulateur.
- **Alternative** : Dagster ou Prefect pour des pipelines Python plus l√©gers, ou des jobs Kubernetes CronJob si seuls quelques scripts sont √† lancer.

---

## üöÄ Scalabilit√© : aujourd'hui et demain

### Capacit√©s actuelles
- Le simulateur sature un CPU autour de ~300k √©v√©nements/s tout en gardant des latences < 1‚ÄØms.
- Le stream-processor est stateless c√¥t√© HTTP : on peut lancer plusieurs r√©plicas derri√®re un load balancer si n√©cessaire.
- Les dashboards s‚Äôappuient sur Prometheus en mode scrape (1 instance suffit pour l‚Äôinstant) et peuvent √™tre clon√©s pour des √©quipes diff√©rentes.

### Limites √† garder en t√™te
- **Transport HTTP** : au-del√† de quelques millions d‚Äô√©v√©nements/s, HTTP devient le goulot. Passage recommand√© sur Kafka + partitions pour absorber le d√©bit.
- **Persistance** : Prometheus n‚Äôest pas con√ßu pour conserver des ann√©es de donn√©es. Pour du long terme il faudra externaliser vers un TSDB (Thanos, Mimir, TimescaleDB).
- **Traitement monolithique** : en cas d‚Äôalgorithmes h√©t√©rog√®nes (ML en ligne, micro-services d‚Äôenrichissement), le code unique deviendra difficile √† scaler.

### Plan d‚Äô√©volution r√©aliste
1. **√âtendre l‚Äôingestion** : activer le mode Kafka d√©j√† esquis√© dans le code (`PROCESSOR_MODE=kafka`) et basculer le simulateur sur un producteur Kafka.
2. **Partitionner le traitement** : extraire la d√©tection d‚Äôanomalies dans un worker (Celery ou Faust) pour parall√©liser selon `car_id`.
3. **S√©parer l‚Äôanalytique** : stocker la t√©l√©m√©trie agr√©g√©e dans un entrep√¥t colonne (BigQuery/Snowflake) pour des dashboards historiques ou du ML.
4. **Automatiser le d√©ploiement** : Helm charts + GitOps (ArgoCD) pour monter plusieurs environnements homog√®nes.

Ces √©tapes suffisent pour passer d‚Äôun laboratoire √† une plateforme qui supporte des centaines de voitures simul√©es ou des flux externes en production.

---

## üõ†Ô∏è D√©veloppement & contributions

1. Cr√©er une branche (`git checkout -b feature/xxx`).
2. Lancer les tests locaux si disponibles (ex. `python -m compileall sensor-simulator/main.py`).
3. Respecter le style Python (type hints, pas de `try/except` autour des imports, logs structur√©s).
4. Soumettre une Pull Request en d√©crivant clairement la modification et les tests ex√©cut√©s.

Des benchmarks, guides d‚Äôusage et cas m√©tiers suppl√©mentaires sont disponibles dans `benchmark/` et `docs/`.

---

## ‚ùì D√©pannage rapide

| Probl√®me | Diagnostic | Solution |
|----------|------------|----------|
| `make start` √©choue | Docker ou docker-compose manquant | Installer Docker Desktop / Compose, ou lancer les services manuellement avec `docker-compose up` |
| `http://localhost:3000` inaccessible | Grafana pas encore d√©marr√© | Patienter quelques secondes ou v√©rifier `docker-compose logs grafana` |
| Pas de m√©triques dans Prometheus | Biblioth√®que `prometheus_client` non install√©e dans le simulateur | Installer la d√©pendance (`pip install prometheus-client`) puis red√©marrer |
| Erreurs HTTP dans le simulateur | Stream-processor injoignable | Lancer `docker-compose up stream-processor` ou ajuster `HTTP_ENDPOINT` |

Pour aller plus loin :
- v√©rifier la sant√© des services (`docker compose ps`),
- consulter les logs (`docker compose logs -f --tail=100 <service>`),
- explorer les runbooks directement dans Grafana (panneaux texte).

---

## üìö Ressources compl√©mentaires

- `ARCHITECTURE.md` ‚Äî d√©tails techniques et flux.
- `sensor-simulator/README.md` ‚Äî fonctionnement du g√©n√©rateur de t√©l√©m√©trie.
- `docs/` ‚Äî cas d‚Äôusage m√©tier, FAQ, notebooks exploratoires.

Bon run !
