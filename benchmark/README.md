# ğŸï¸ Ferrari F1 IoT Smart Pit-Stop - Benchmark Suite

## Vue d'ensemble

Ce dossier contient la **suite de tests de performance et de scalabilitÃ©** pour le projet Ferrari IoT Smart Pit-Stop. Les tests dÃ©montrent :

- âœ… **Performance**: CapacitÃ© Ã  traiter 500-5000 messages/seconde en temps rÃ©el
- âœ… **ScalabilitÃ©**: Comportement du systÃ¨me sous diffÃ©rentes charges
- âœ… **FiabilitÃ©**: Taux de succÃ¨s et dÃ©tection d'anomalies
- âœ… **EfficacitÃ©**: Utilisation des ressources (CPU, mÃ©moire)

---

## ğŸ“ Structure

```
benchmark/
â”œâ”€â”€ run_tests.py          # Script principal de benchmark
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ config.yml           # Configuration des tests
â”œâ”€â”€ README.md            # Cette documentation
â””â”€â”€ benchmark_run.log    # Logs d'exÃ©cution (gÃ©nÃ©rÃ©)
```

---

## ğŸš€ Utilisation

### Installation des dÃ©pendances

```bash
cd benchmark/
pip install -r requirements.txt
```

### PrÃ©requis

Avant de lancer les tests, assurez-vous que la stack de monitoring est dÃ©marrÃ©e :

```bash
cd ../monitoring/
./deploy-monitoring.sh start
```

VÃ©rifiez que tous les services sont opÃ©rationnels :
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000
- Sensor Simulator: http://localhost:8000
- Stream Processor: http://localhost:8001

### ExÃ©cution des tests

```bash
python run_tests.py
```

Le script va :
1. VÃ©rifier la santÃ© de tous les services
2. ExÃ©cuter les 3 scÃ©narios de test (500, 1000, 5000 msg/s)
3. Collecter les mÃ©triques via Prometheus API
4. GÃ©nÃ©rer les rapports dans `docs/`

**DurÃ©e estimÃ©e** : ~5-6 minutes (3 tests de 60s + pauses)

---

## ğŸ“Š ScÃ©narios de test

### Test 1 : Charge Faible (500 msg/s)
- **Objectif** : Valider le fonctionnement nominal
- **DurÃ©e** : 60 secondes
- **Attendu** : Latence trÃ¨s faible, ressources minimales

### Test 2 : Charge Normale (1000 msg/s)
- **Objectif** : Performance en production
- **DurÃ©e** : 60 secondes
- **Attendu** : Latence P95 <50ms, CPU <70%

### Test 3 : Stress Test (5000 msg/s)
- **Objectif** : Tester les limites du systÃ¨me
- **DurÃ©e** : 60 secondes
- **Attendu** : SystÃ¨me stable, possibilitÃ© d'auto-scaling

---

## ğŸ“ˆ MÃ©triques collectÃ©es

### Latence (via Prometheus)
- **P50** : MÃ©diane (50% des requÃªtes)
- **P95** : 95Ã¨me percentile
- **P99** : 99Ã¨me percentile
- **Moyenne** : Latence moyenne
- **Min/Max** : Valeurs extrÃªmes

**Source** : `processing_latency_seconds_bucket{job="stream-processor"}`

### DÃ©bit
- **DÃ©bit cible** : Messages/seconde attendus
- **DÃ©bit rÃ©el** : Messages/seconde effectifs
- **Total messages** : Nombre total traitÃ©
- **Taux de succÃ¨s** : Pourcentage de messages rÃ©ussis

**Source** : `messages_processed_total`, `messages_failed_total`

### Ressources (via cAdvisor)
- **CPU** : Utilisation en %
- **MÃ©moire** : Usage en MB
- **RÃ©seau** : DonnÃ©es RX/TX en MB

**Source** : `container_cpu_usage_seconds_total`, `container_memory_usage_bytes`

### Anomalies
- **Total dÃ©tectÃ©es** : Nombre d'anomalies trouvÃ©es
- **Par type** : Freins, pneus, etc.
- **Taux de dÃ©tection** : Pourcentage dÃ©tectÃ©

**Source** : `anomalies_detected_total{type="..."}`

---

## âš™ï¸ Configuration

Le fichier `config.yml` permet de personnaliser :

### Endpoints
```yaml
endpoints:
  prometheus: 'http://localhost:9090'
  sensor_simulator: 'http://localhost:8000'
  stream_processor: 'http://localhost:8001'
```

### ScÃ©narios
```yaml
test_scenarios:
  - throughput: 500
    duration: 60
  - throughput: 1000
    duration: 60
  # Ajoutez vos propres scÃ©narios
```

### Seuils de validation
```yaml
thresholds:
  latency_p95_ms: 50
  cpu_percent_max: 85
  success_rate_min: 99.0
```

---

## ğŸ“„ Rapports gÃ©nÃ©rÃ©s

### docs/benchmarks.md
Rapport Markdown complet avec :
- RÃ©sumÃ© exÃ©cutif
- Tableau rÃ©capitulatif des tests
- DÃ©tails par test (latence, dÃ©bit, ressources)
- Graphiques ASCII
- Analyse et recommandations

### docs/benchmark_results.json
RÃ©sultats bruts en JSON pour analyse ultÃ©rieure :
```json
{
  "metadata": {
    "timestamp": "2025-10-14T...",
    "duration_seconds": 360,
    "test_count": 3
  },
  "results": [...]
}
```

---

## ğŸ¯ CritÃ¨res de succÃ¨s

Un test est considÃ©rÃ© comme **PASSED** si :
- âœ… Latence P95 â‰¤ 50ms
- âœ… Taux de succÃ¨s â‰¥ 99%
- âœ… CPU â‰¤ 85% (avant auto-scaling)
- âœ… Aucune dÃ©faillance systÃ¨me

Un test **FAILED** si :
- âŒ Latence excessive
- âŒ Taux d'Ã©chec Ã©levÃ©
- âŒ Saturation des ressources

---

## ğŸ” Exemple de rÃ©sultats

```
Test: Benchmark_1000msg_s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Latence:
  P50: 8.45ms
  P95: 22.31ms
  P99: 38.67ms

DÃ©bit:
  Cible: 1000 msg/s
  RÃ©el: 987 msg/s
  Taux succÃ¨s: 99.7%

Ressources:
  CPU: 68.3%
  MÃ©moire: 512 MB

Status: âœ… PASSED
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : Services non accessibles

```bash
# VÃ©rifier que la stack monitoring tourne
cd ../monitoring/
docker-compose ps

# RedÃ©marrer si nÃ©cessaire
./deploy-monitoring.sh restart
```

### ProblÃ¨me : MÃ©triques Prometheus vides

```bash
# VÃ©rifier les targets Prometheus
curl http://localhost:9090/api/v1/targets

# VÃ©rifier que les services exposent /metrics
curl http://localhost:8001/metrics
curl http://localhost:8000/metrics
```

### ProblÃ¨me : Tests Ã©chouent

- Augmenter les seuils dans `config.yml`
- VÃ©rifier les ressources systÃ¨me (Docker)
- RÃ©duire le dÃ©bit cible des tests
- Augmenter la durÃ©e de warmup

---

## ğŸ“š Architecture du script

### Classes principales

#### `FerrariF1Benchmark`
Gestionnaire principal des tests de performance.

**MÃ©thodes clÃ©s** :
- `check_services_health()` : VÃ©rifie la disponibilitÃ© des services
- `run_single_test()` : ExÃ©cute un test unique
- `run_all_tests()` : ExÃ©cute tous les scÃ©narios
- `query_prometheus()` : Interroge l'API Prometheus
- `get_latency_metrics()` : Collecte mÃ©triques de latence
- `get_resource_metrics()` : Collecte mÃ©triques de ressources
- `generate_markdown_report()` : GÃ©nÃ¨re le rapport

#### Dataclasses
- `LatencyMetrics` : MÃ©triques de latence (p50, p95, p99...)
- `ResourceMetrics` : MÃ©triques de ressources (CPU, RAM...)
- `ThroughputMetrics` : MÃ©triques de dÃ©bit
- `AnomalyMetrics` : MÃ©triques d'anomalies
- `BenchmarkResult` : RÃ©sultat complet d'un test

---

## ğŸ”— IntÃ©gration continue

### Automatiser avec Airflow

Le DAG `ferrari_grand_prix_dag.py` peut Ãªtre Ã©tendu pour inclure le benchmark :

```python
benchmark_task = PythonOperator(
    task_id='run_performance_benchmark',
    python_callable=run_benchmark,
    dag=dag
)

batch_analysis >> benchmark_task >> send_notification
```

### GitHub Actions

```yaml
- name: Run Performance Benchmark
  run: |
    cd benchmark/
    python run_tests.py
    
- name: Upload Benchmark Report
  uses: actions/upload-artifact@v3
  with:
    name: benchmark-report
    path: docs/benchmarks.md
```

---

## ğŸ“– RÃ©fÃ©rences

- **Prometheus API** : https://prometheus.io/docs/prometheus/latest/querying/api/
- **PromQL** : https://prometheus.io/docs/prometheus/latest/querying/basics/
- **cAdvisor Metrics** : https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md

---

## ğŸï¸ Livrable Projet

Ce benchmark constitue le livrable **"Cluster setup + benchmark results (performance & scalability)"** :

âœ… **Cluster Setup** : Stack Docker Compose / Kubernetes configurÃ©e

âœ… **Performance** : Tests Ã  500, 1000, 5000 msg/s

âœ… **Scalability** : DÃ©monstration de l'auto-scaling HPA

âœ… **Results** : Rapport dÃ©taillÃ© avec mÃ©triques et graphiques

âœ… **Reproducibility** : Scripts automatisÃ©s et configuration

---

**ğŸï¸ Forza Ferrari! ğŸï¸**
